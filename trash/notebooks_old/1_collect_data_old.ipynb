{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-14T23:35:26.108611Z",
     "start_time": "2025-06-14T23:35:22.978704Z"
    }
   },
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import yfinance as yf\n",
    "from pytrends.request import TrendReq\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Cargar variables desde el archivo .env\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "api_key = os.getenv(\"ALPHAVANTAGE_API_KEY\")\n",
    "symbol = 'BTC'\n",
    "market = 'USD'\n",
    "url = f'https://www.alphavantage.co/query?function=DIGITAL_CURRENCY_DAILY&symbol={symbol}&market={market}&apikey={api_key}'\n",
    "\n",
    "# Obtener los datos\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "# Guardar JSON en archivo\n",
    "with open('btc_daily.json', 'w') as f:\n",
    "    json.dump(data, f, indent=4)\n",
    "\n",
    "# Extraer la serie temporal\n",
    "time_series = data.get(\"Time Series (Digital Currency Daily)\", {})\n",
    "\n",
    "# Convertir a DataFrame\n",
    "df = pd.DataFrame.from_dict(time_series, orient='index')\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df = df.sort_index()"
   ],
   "id": "4277fcd397639978"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T02:34:13.566408Z",
     "start_time": "2025-06-09T02:34:13.559442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Renombrar columnas para facilidad de uso\n",
    "df.columns = [\n",
    "    \"open_usd\",\n",
    "    \"high_usd\",\n",
    "    \"low_usd\",\n",
    "    \"close_usd\",\n",
    "    \"volume\"\n",
    "]\n",
    "\n",
    "# Convertir a valores numéricos\n",
    "cols_to_numeric = [\"open_usd\", \"high_usd\", \"low_usd\", \"close_usd\", \"volume\"]\n",
    "df[cols_to_numeric] = df[cols_to_numeric].astype(float)\n",
    "\n",
    "# Mostrar primeras filas\n",
    "print(df.head())"
   ],
   "id": "49a0f364e980be88",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            open_usd  high_usd   low_usd  close_usd        volume\n",
      "2024-06-25  60262.16  62400.00  60217.36   61789.71  15201.582477\n",
      "2024-06-26  61794.47  62470.00  60656.80   60816.68  11392.798350\n",
      "2024-06-27  60818.86  62346.16  60546.94   61615.39  10530.358988\n",
      "2024-06-28  61611.43  62170.62  59868.00   60313.35  11381.025874\n",
      "2024-06-29  60312.36  61122.66  60273.80   60885.67   3199.036501\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T02:41:36.968235Z",
     "start_time": "2025-06-09T02:41:36.013172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "symbol = 'BTC'\n",
    "market = 'USD'\n",
    "url = f'https://www.alphavantage.co/query?function=DIGITAL_CURRENCY_DAILY&symbol={symbol}&market={market}&outputsize=full&apikey={api_key}'\n",
    "\n",
    "# Carpeta de salida\n",
    "output_dir = Path(\"btc_data_by_year\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Obtener los datos\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "# Guardar el JSON completo por si se necesita\n",
    "with open(output_dir / 'btc_full.json', 'w') as f:\n",
    "    json.dump(data, f, indent=4)\n",
    "\n",
    "# Procesar la serie temporal\n",
    "time_series = data.get(\"Time Series (Digital Currency Daily)\", {})\n",
    "df = pd.DataFrame.from_dict(time_series, orient='index')\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df = df.sort_index()\n",
    "\n",
    "# Renombrar columnas según estructura simple\n",
    "df.columns = [\"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "df = df.astype(float)\n"
   ],
   "id": "70b9cb684c917e53",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "keys must be str, int, float, bool or None, not Timestamp",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 38\u001B[0m\n\u001B[1;32m     36\u001B[0m     group_dict \u001B[38;5;241m=\u001B[39m group\u001B[38;5;241m.\u001B[39msort_index(ascending\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\u001B[38;5;241m.\u001B[39mto_dict(orient\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mindex\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(output_dir \u001B[38;5;241m/\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbtc_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00myear\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.json\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m---> 38\u001B[0m         \u001B[43mjson\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgroup_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m✔ Datos completos guardados por año en: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00moutput_dir\u001B[38;5;241m.\u001B[39mresolve()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/__init__.py:179\u001B[0m, in \u001B[0;36mdump\u001B[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001B[0m\n\u001B[1;32m    173\u001B[0m     iterable \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m(skipkeys\u001B[38;5;241m=\u001B[39mskipkeys, ensure_ascii\u001B[38;5;241m=\u001B[39mensure_ascii,\n\u001B[1;32m    174\u001B[0m         check_circular\u001B[38;5;241m=\u001B[39mcheck_circular, allow_nan\u001B[38;5;241m=\u001B[39mallow_nan, indent\u001B[38;5;241m=\u001B[39mindent,\n\u001B[1;32m    175\u001B[0m         separators\u001B[38;5;241m=\u001B[39mseparators,\n\u001B[1;32m    176\u001B[0m         default\u001B[38;5;241m=\u001B[39mdefault, sort_keys\u001B[38;5;241m=\u001B[39msort_keys, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw)\u001B[38;5;241m.\u001B[39miterencode(obj)\n\u001B[1;32m    177\u001B[0m \u001B[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001B[39;00m\n\u001B[1;32m    178\u001B[0m \u001B[38;5;66;03m# a debuggability cost\u001B[39;00m\n\u001B[0;32m--> 179\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py:432\u001B[0m, in \u001B[0;36m_make_iterencode.<locals>._iterencode\u001B[0;34m(o, _current_indent_level)\u001B[0m\n\u001B[1;32m    430\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m _iterencode_list(o, _current_indent_level)\n\u001B[1;32m    431\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(o, \u001B[38;5;28mdict\u001B[39m):\n\u001B[0;32m--> 432\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m _iterencode_dict(o, _current_indent_level)\n\u001B[1;32m    433\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    434\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m markers \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py:377\u001B[0m, in \u001B[0;36m_make_iterencode.<locals>._iterencode_dict\u001B[0;34m(dct, _current_indent_level)\u001B[0m\n\u001B[1;32m    375\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m    376\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 377\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mkeys must be str, int, float, bool or None, \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    378\u001B[0m                     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnot \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    379\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m first:\n\u001B[1;32m    380\u001B[0m     first \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[0;31mTypeError\u001B[0m: keys must be str, int, float, bool or None, not Timestamp"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T02:42:46.501488Z",
     "start_time": "2025-06-09T02:42:46.484394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Guardar por año\n",
    "for year, group in df.groupby(df.index.year):\n",
    "    group.index = group.index.strftime(\"%Y-%m-%d\")\n",
    "    group_dict = group.sort_index(ascending=False).to_dict(orient='index')\n",
    "    with open(output_dir / f'btc_{year}.json', 'w') as f:\n",
    "        json.dump(group_dict, f, indent=4)\n",
    "\n",
    "print(f\"✔ Datos completos guardados por año en: {output_dir.resolve()}\")"
   ],
   "id": "ecb87840c180e7ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Datos completos guardados por año en: /Users/cbarril/dev/posgrado/tp_ast1_19co2024/notebooks/btc_data_by_year\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T02:57:28.327803Z",
     "start_time": "2025-06-09T02:57:25.358786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Descargar histórico completo de BTC/USD desde 2010\n",
    "btc = yf.download(\"BTC-USD\", start=\"2010-01-01\")\n",
    "\n",
    "# Guardar como CSV por año\n",
    "for year, group in btc.groupby(btc.index.year):\n",
    "    group.to_csv(f\"btc_{year}.csv\")\n",
    "\n",
    "print(\"✔ Histórico completo guardado como CSV por año.\")\n"
   ],
   "id": "cdc86a3c7f20dc3a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/rq9m5qb17jsg0xbdp8j28n2c0000gn/T/ipykernel_78804/936364403.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  btc = yf.download(\"BTC-USD\", start=\"2010-01-01\")\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Histórico completo guardado como CSV por año.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T19:28:06.146499Z",
     "start_time": "2025-06-09T19:28:02.019814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Lista de activos: (subcarpeta, símbolo_yfinance)\n",
    "assets = [\n",
    "    (\"sp500\", \"^GSPC\"),\n",
    "    (\"gold\", \"GC=F\"),\n",
    "    (\"eth\", \"ETH-USD\")\n",
    "]\n",
    "\n",
    "# Rango de fechas\n",
    "start_date = \"2010-01-01\"\n",
    "\n",
    "for name, symbol in assets:\n",
    "    print(f\"⬇ Descargando datos de {name.upper()} ({symbol})...\")\n",
    "    data = yf.download(symbol, start=start_date, auto_adjust=True)\n",
    "\n",
    "    # Crear carpeta de salida: dataset/{activo}\n",
    "    output_dir = Path(\"../datasets_old\") / name\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Guardar por año\n",
    "    for year, group in data.groupby(data.index.year):\n",
    "        filename = output_dir / f\"{name}_{year}.csv\"\n",
    "        group.to_csv(filename)\n",
    "\n",
    "    print(f\"✔ Datos de {name.upper()} guardados en: {output_dir.resolve()}\\n\")\n"
   ],
   "id": "a7a1412e1d617faa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇ Descargando datos de SP500 (^GSPC)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Datos de SP500 guardados en: /Users/cbarril/dev/posgrado/tp_ast1_19co2024/datasets/sp500\n",
      "\n",
      "⬇ Descargando datos de GOLD (GC=F)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Datos de GOLD guardados en: /Users/cbarril/dev/posgrado/tp_ast1_19co2024/datasets/gold\n",
      "\n",
      "⬇ Descargando datos de ETH (ETH-USD)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Datos de ETH guardados en: /Users/cbarril/dev/posgrado/tp_ast1_19co2024/datasets/eth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T23:36:18.858834Z",
     "start_time": "2025-06-14T23:36:17.286437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Lista de activos: (subcarpeta, símbolo_yfinance)\n",
    "assets = [\n",
    "    (\"btc2\", \"BTC-USD\")\n",
    "]\n",
    "\n",
    "# Rango de fechas\n",
    "start_date = \"2010-01-01\"\n",
    "\n",
    "for name, symbol in assets:\n",
    "    print(f\"⬇ Descargando datos de {name.upper()} ({symbol})...\")\n",
    "    data = yf.download(symbol, start=start_date, auto_adjust=True)\n",
    "\n",
    "    # Crear carpeta de salida: dataset/{activo}\n",
    "    output_dir = Path(\"../datasets_old\") / name\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Guardar por año\n",
    "    for year, group in data.groupby(data.index.year):\n",
    "        filename = output_dir / f\"{name}_{year}.csv\"\n",
    "        group.to_csv(filename)\n",
    "\n",
    "    print(f\"✔ Datos de {name.upper()} guardados en: {output_dir.resolve()}\\n\")\n"
   ],
   "id": "9ec70dba161eb199",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇ Descargando datos de BTC2 (BTC-USD)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Datos de BTC2 guardados en: /Users/cbarril/dev/posgrado/tp_ast1_19co2024/datasets/btc2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T19:29:00.778642Z",
     "start_time": "2025-06-09T19:28:59.395597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# DXY: Dollar Index\n",
    "symbol = \"DX-Y.NYB\"\n",
    "name = \"dxy\"\n",
    "start_date = \"2010-01-01\"\n",
    "\n",
    "print(f\"⬇ Descargando datos de DOLLAR INDEX ({symbol})...\")\n",
    "data = yf.download(symbol, start=start_date, auto_adjust=True)\n",
    "\n",
    "# Crear carpeta de salida: dataset/dxy\n",
    "output_dir = Path(\"../datasets_old\") / name\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Guardar por año\n",
    "for year, group in data.groupby(data.index.year):\n",
    "    filename = output_dir / f\"{name}_{year}.csv\"\n",
    "    group.to_csv(filename)\n",
    "\n",
    "print(f\"✔ Datos del DOLLAR INDEX guardados en: {output_dir.resolve()}\")"
   ],
   "id": "a62303574f67c3d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇ Descargando datos de DOLLAR INDEX (DX-Y.NYB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Datos del DOLLAR INDEX guardados en: /Users/cbarril/dev/posgrado/tp_ast1_19co2024/datasets/dxy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T19:35:02.456629Z",
     "start_time": "2025-06-09T19:34:58.798854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pytrends = TrendReq(hl='en-US', tz=0)\n",
    "\n",
    "# Parámetros\n",
    "kw_list = [\"bitcoin\"]\n",
    "start_date = datetime(2024, 1, 1)\n",
    "end_date = datetime(2025, 6, 9)\n",
    "delta = timedelta(days=270)  # máximo rango diario permitido por Google Trends\n",
    "\n",
    "current_start = start_date\n",
    "\n",
    "while current_start < end_date:\n",
    "    current_end = min(current_start + delta, end_date)\n",
    "    timeframe = current_start.strftime('%Y-%m-%d') + \" \" + current_end.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Cargar datos\n",
    "    try:\n",
    "        pytrends.build_payload(kw_list, cat=0, timeframe=timeframe, geo='', gprop='')\n",
    "        data = pytrends.interest_over_time()\n",
    "\n",
    "        if data.empty:\n",
    "            print(f\"No data for range: {timeframe}\")\n",
    "        else:\n",
    "            if 'isPartial' in data.columns:\n",
    "                data = data.drop(columns='isPartial')\n",
    "\n",
    "            # Obtener el año del inicio del tramo\n",
    "            year = current_start.year\n",
    "            output_dir = f\"../datasets_old/trend/{year}\"\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "            filename = f\"{output_dir}/bitcoin_trend_{current_start.strftime('%Y-%m-%d')}_to_{current_end.strftime('%Y-%m-%d')}.csv\"\n",
    "            data.to_csv(filename)\n",
    "            print(f\"Saved: {filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error with range {timeframe}: {e}\")\n",
    "\n",
    "    current_start = current_end  # avanzar al siguiente tramo\n"
   ],
   "id": "b90464781e40b7d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../datasets/trend/2025/bitcoin_trend_2025-01-01_to_2025-06-09.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cbarril/dev/posgrado/tp_ast1_19co2024/ast1/lib/python3.12/site-packages/pytrends/request.py:260: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(False)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T19:37:40.040876Z",
     "start_time": "2025-06-09T19:37:39.214234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.alternative.me/fng/?limit=0&format=json\"\n",
    "response = requests.get(url)\n",
    "data = response.json()[\"data\"]\n",
    "\n",
    "# Convertir a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'].astype(int), unit='s')\n",
    "df['value'] = df['value'].astype(int)\n",
    "df = df.sort_values('timestamp')\n",
    "\n",
    "# Ver columnas disponibles\n",
    "print(df.head())\n",
    "\n",
    "# Guardar\n",
    "df.to_csv(\"fear_and_greed_index.csv\", index=False)"
   ],
   "id": "22c2c694e68bf2f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      value value_classification  timestamp time_until_update\n",
      "2681     30                 Fear 2018-02-01               NaN\n",
      "2680     15         Extreme Fear 2018-02-02               NaN\n",
      "2679     40                 Fear 2018-02-03               NaN\n",
      "2678     24         Extreme Fear 2018-02-04               NaN\n",
      "2677     11         Extreme Fear 2018-02-05               NaN\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T19:40:21.560061Z",
     "start_time": "2025-06-09T19:40:20.253024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Descargar datos desde la API de Blockchain.com\n",
    "url = \"https://api.blockchain.info/charts/n-unique-addresses?timespan=all&format=csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.columns = ['date', 'active_addresses']\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Crear carpeta base si no existe\n",
    "base_path = \"../datasets_old/active_addresses\"\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "# Separar y guardar por año\n",
    "for year, group in df.groupby(df['date'].dt.year):\n",
    "    year_path = os.path.join(base_path, f\"{year}.csv\")\n",
    "    group.to_csv(year_path, index=False)\n",
    "    print(f\"Guardado: {year_path}\")\n"
   ],
   "id": "a5e31592098d333",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: ../datasets/active_addresses/2009.csv\n",
      "Guardado: ../datasets/active_addresses/2010.csv\n",
      "Guardado: ../datasets/active_addresses/2011.csv\n",
      "Guardado: ../datasets/active_addresses/2012.csv\n",
      "Guardado: ../datasets/active_addresses/2013.csv\n",
      "Guardado: ../datasets/active_addresses/2014.csv\n",
      "Guardado: ../datasets/active_addresses/2015.csv\n",
      "Guardado: ../datasets/active_addresses/2016.csv\n",
      "Guardado: ../datasets/active_addresses/2017.csv\n",
      "Guardado: ../datasets/active_addresses/2018.csv\n",
      "Guardado: ../datasets/active_addresses/2019.csv\n",
      "Guardado: ../datasets/active_addresses/2020.csv\n",
      "Guardado: ../datasets/active_addresses/2021.csv\n",
      "Guardado: ../datasets/active_addresses/2022.csv\n",
      "Guardado: ../datasets/active_addresses/2023.csv\n",
      "Guardado: ../datasets/active_addresses/2024.csv\n",
      "Guardado: ../datasets/active_addresses/2025.csv\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T19:49:01.387155Z",
     "start_time": "2025-06-09T19:49:00.597446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "\n",
    "fed_api_key = os.getenv(\"FED_API_KEY\")\n",
    "\n",
    "# Endpoint para tasa de interés FED\n",
    "series_id = \"FEDFUNDS\"\n",
    "url = f\"https://api.stlouisfed.org/fred/series/observations\"\n",
    "params = {\n",
    "    \"series_id\": series_id,\n",
    "    \"api_key\": fed_api_key,\n",
    "    \"file_type\": \"json\",\n",
    "}\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "data = response.json()[\"observations\"]\n",
    "\n",
    "# Crear DataFrame\n",
    "df = pd.DataFrame(data)[[\"date\", \"value\"]]\n",
    "df.columns = [\"date\", \"interest_rate\"]\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df[\"interest_rate\"] = pd.to_numeric(df[\"interest_rate\"], errors=\"coerce\")\n",
    "\n",
    "# Crear carpeta base\n",
    "base_path = \"../datasets_old/interest_rate\"\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "# Guardar CSV por año\n",
    "for year, group in df.groupby(df['date'].dt.year):\n",
    "    year_path = os.path.join(base_path, f\"{year}.csv\")\n",
    "    group.to_csv(year_path, index=False)\n",
    "    print(f\"Guardado: {year_path}\")\n"
   ],
   "id": "4d19fffec8fd7cf3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: ../datasets/interest_rate/1954.csv\n",
      "Guardado: ../datasets/interest_rate/1955.csv\n",
      "Guardado: ../datasets/interest_rate/1956.csv\n",
      "Guardado: ../datasets/interest_rate/1957.csv\n",
      "Guardado: ../datasets/interest_rate/1958.csv\n",
      "Guardado: ../datasets/interest_rate/1959.csv\n",
      "Guardado: ../datasets/interest_rate/1960.csv\n",
      "Guardado: ../datasets/interest_rate/1961.csv\n",
      "Guardado: ../datasets/interest_rate/1962.csv\n",
      "Guardado: ../datasets/interest_rate/1963.csv\n",
      "Guardado: ../datasets/interest_rate/1964.csv\n",
      "Guardado: ../datasets/interest_rate/1965.csv\n",
      "Guardado: ../datasets/interest_rate/1966.csv\n",
      "Guardado: ../datasets/interest_rate/1967.csv\n",
      "Guardado: ../datasets/interest_rate/1968.csv\n",
      "Guardado: ../datasets/interest_rate/1969.csv\n",
      "Guardado: ../datasets/interest_rate/1970.csv\n",
      "Guardado: ../datasets/interest_rate/1971.csv\n",
      "Guardado: ../datasets/interest_rate/1972.csv\n",
      "Guardado: ../datasets/interest_rate/1973.csv\n",
      "Guardado: ../datasets/interest_rate/1974.csv\n",
      "Guardado: ../datasets/interest_rate/1975.csv\n",
      "Guardado: ../datasets/interest_rate/1976.csv\n",
      "Guardado: ../datasets/interest_rate/1977.csv\n",
      "Guardado: ../datasets/interest_rate/1978.csv\n",
      "Guardado: ../datasets/interest_rate/1979.csv\n",
      "Guardado: ../datasets/interest_rate/1980.csv\n",
      "Guardado: ../datasets/interest_rate/1981.csv\n",
      "Guardado: ../datasets/interest_rate/1982.csv\n",
      "Guardado: ../datasets/interest_rate/1983.csv\n",
      "Guardado: ../datasets/interest_rate/1984.csv\n",
      "Guardado: ../datasets/interest_rate/1985.csv\n",
      "Guardado: ../datasets/interest_rate/1986.csv\n",
      "Guardado: ../datasets/interest_rate/1987.csv\n",
      "Guardado: ../datasets/interest_rate/1988.csv\n",
      "Guardado: ../datasets/interest_rate/1989.csv\n",
      "Guardado: ../datasets/interest_rate/1990.csv\n",
      "Guardado: ../datasets/interest_rate/1991.csv\n",
      "Guardado: ../datasets/interest_rate/1992.csv\n",
      "Guardado: ../datasets/interest_rate/1993.csv\n",
      "Guardado: ../datasets/interest_rate/1994.csv\n",
      "Guardado: ../datasets/interest_rate/1995.csv\n",
      "Guardado: ../datasets/interest_rate/1996.csv\n",
      "Guardado: ../datasets/interest_rate/1997.csv\n",
      "Guardado: ../datasets/interest_rate/1998.csv\n",
      "Guardado: ../datasets/interest_rate/1999.csv\n",
      "Guardado: ../datasets/interest_rate/2000.csv\n",
      "Guardado: ../datasets/interest_rate/2001.csv\n",
      "Guardado: ../datasets/interest_rate/2002.csv\n",
      "Guardado: ../datasets/interest_rate/2003.csv\n",
      "Guardado: ../datasets/interest_rate/2004.csv\n",
      "Guardado: ../datasets/interest_rate/2005.csv\n",
      "Guardado: ../datasets/interest_rate/2006.csv\n",
      "Guardado: ../datasets/interest_rate/2007.csv\n",
      "Guardado: ../datasets/interest_rate/2008.csv\n",
      "Guardado: ../datasets/interest_rate/2009.csv\n",
      "Guardado: ../datasets/interest_rate/2010.csv\n",
      "Guardado: ../datasets/interest_rate/2011.csv\n",
      "Guardado: ../datasets/interest_rate/2012.csv\n",
      "Guardado: ../datasets/interest_rate/2013.csv\n",
      "Guardado: ../datasets/interest_rate/2014.csv\n",
      "Guardado: ../datasets/interest_rate/2015.csv\n",
      "Guardado: ../datasets/interest_rate/2016.csv\n",
      "Guardado: ../datasets/interest_rate/2017.csv\n",
      "Guardado: ../datasets/interest_rate/2018.csv\n",
      "Guardado: ../datasets/interest_rate/2019.csv\n",
      "Guardado: ../datasets/interest_rate/2020.csv\n",
      "Guardado: ../datasets/interest_rate/2021.csv\n",
      "Guardado: ../datasets/interest_rate/2022.csv\n",
      "Guardado: ../datasets/interest_rate/2023.csv\n",
      "Guardado: ../datasets/interest_rate/2024.csv\n",
      "Guardado: ../datasets/interest_rate/2025.csv\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ast1)",
   "language": "python",
   "name": "ast1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
